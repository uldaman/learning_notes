# 编码/解码
任何数据在内存中都是以二进制的形式保存, 也就是说一个文本文件, 不管你看到的是中文还是英文或者是法文, 它在内存也都是一串二进制数据 (或者说是一串字节数组), 那么当用一个文本浏览器打开一个文本文件时, 该文本浏览器就会拿它读出来的字节数组去 "查字典", 然后将查到的结果展现出来.

这个 "查字典" 的动作就被称之为**解码**, 同时也不叫它 "查字典", 而叫它查码表, 常见的码表有 ASCII、ISO-8859-1、GB2312、GBK、UTF-8、UTF-16 等.

(解码, 解码, 可以理解成**破解密码**, 二进制数据相当于密码, 人眼不可识别, 你需要把这串密码破解出来才能知道它是什么内容, 所以叫解码).

相对的, 将可识别的文字转换成字节数组的过程就称之为**编码**, 根据使用的码表不同, 同样的文字会被编码成不同的字节数组.

![](http://i64.tinypic.com/2012gz5.jpg)

# native2ascii 简介
native2ascii 是 sun java sdk 提供的一个工具, 用来将文本类文件 (比如 `*.txt`、`*.ini` 等等) 转为 Unicode 编码.

**为什么要进行转码?**

原因在于程序的国际化, 来看下 Unicode 编码的定义:<br>
Unicode (统一码、万国码、单一码) 是一种在计算机上使用的字符编码, 它为每种语言中的每个字符设定了统一并且唯一的二进制编码, 以满足跨语言、跨平台进行文本转换、处理的要求;<br>
1990 年开始研发, 1994 年正式公布, 随着计算机工作能力的增强, Unicode 也在面世以来的十多年里得到普及.

简单的理解, 也就是说 Unicode 是个全球通用的 "字典".

而 JAVAC 是以系统默认编码读入源文件, 然后按 UNICODE 进行编码, 也就是说有 "bytes" \-\> "encode 字符" \-\> "Unicode 字符" 的转换;<br>
那么, 如果一开始, 源文件是在中国的电脑上开发出来的, 它很可能是 GBK 编码, 然后移植到外国的电脑上, 外国的电脑以系统默认编码读入源文件, 但是很遗憾, 外国的电脑的系统默认编码可不是 GBK, 所以在 "bytes" \-\> "encode 字符" 这一步就会出错.

# 获取 native2ascii
安装了 jdk 后, 假如你是在 windows 上安装, 那么在 jdk 的安装目录下, 会有一个 bin 目录, 其中 native2ascii.exe 正是.

# 命令格式
`native2ascii -[options] [inputfile [outputfile]]`

说明:

- [options]: 表示命令开关, 有两个选项可供选择
    + reverse: 将Unicode编码转为本地或者指定编码, 不指定编码情况下, 将转为本地编码
    + encoding encoding\_name: 读取源文件所采用的编码方式
- [inputfile [outputfile]]
    + inputfile: 表示输入文件全名
    + outputfile: 输出文件名. 如果缺少此参数, 将输出到控制台
